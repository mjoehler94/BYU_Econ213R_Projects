{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposal for Final Project\n",
    "#### 10/23/2018\n",
    "Team Members:\n",
    "- Matt Oehler\n",
    "___\n",
    "\n",
    "#### Problem Statement\n",
    "- For my project I intend to explore natural language processing applications of machine learning. Ultimately I plan compare multiple algorithms in their success at classify documents according to their subject. I feel like text data is becoming more and more available, and having a skill set to readily analyze text data will make me more valuable in industry. Since we haven't specifically covered NLP in this class, I will first explore easier NLP tasks to familiarize myself with the process and learn some of the different methodologies. One method of data processing that I am planning to explore in depth is the process of word embedding (representing words in a vector space which allows them to be assessed quantitatively while maintaining contextual meaning and relationships)\n",
    "\n",
    "#### Outline\n",
    "- Show that for simpe NLP tasks, machine learning is a viable solution\n",
    "    - (use text classification as an example)\n",
    "- Show that using word embedding techniques, machine learning can be used to approach more complicated NLP tasks\n",
    "- Train and evaluate multiple models on the same dataset performing the same task to see if certain models seems to work better\n",
    "    - My current plan is to train models on a multiclass classification problem (ie automatically classifying documents into different categories based on content). This may as I encounter unforeseen obstacles along the way.\n",
    "- Summarize and discuss results\n",
    "\n",
    "#### Data Sources\n",
    "- The UCI Data Repository has a pre-cleaned dataset of text messages that are classified as spam or not spam. This dataset would be used just for familiarizing myself with some basic NLP methodologies.\n",
    "- [UCI Sentence Classificatoin Datset](http://archive.ics.uci.edu/ml/datasets/Sentence+Classification#) Use paper introductions/abstracts to identify the topic of the paper\n",
    "\n",
    "- Web scraping [fivethirtyeight](https://fivethirtyeight.com/) blog posts: These blogposts are already organized by topic and once I have a trained model I think that these could be scraped and turned into a useable labeled data set without too much effort.\n",
    "\n",
    "#### Supplementary Research\n",
    "- [Automatic Document Classification](https://cloud.google.com/blog/products/gcp/problem-solving-with-ml-automatic-document-classification)\n",
    "- [Representation of Sentences and Paragraphs](https://cs.stanford.edu/~quocle/paragraph_vector.pdf)\n",
    "- [Word2Vec Representations](https://imrsv.ai/blog/2017/5/12/semantic-averaging-of-documents-using-word2vec-representations)\n",
    "\n",
    "___\n",
    "\n",
    "### Samples of Data I will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sms dataset for learning basic NLP applications and methodologies\n",
    "sms = pd.read_table('SMSSpamCollection',\n",
    "                   sep='\\t', \n",
    "                   header=None, \n",
    "                   names=['label', 'text'])\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x40476 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 74 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labeled conference abstracts (a multiclass classification dataset for what will most likely be the basis of the final project)\n",
    "# I will compare multiple NLP approaches using this dataset to see if certain methods seem better than others\n",
    "\n",
    "\n",
    "#samples:\n",
    "\n",
    "#format: category\t introduction/abstract\n",
    "\n",
    "### abstract ###\n",
    "# AIMX\tthe paper extends research on fixed-pie perceptions by suggesting that disputants may prefer proposals that are perceived to be equally attractive to both parties i e , balanced rather than one-sided, because balanced agreements are seen as more likely to be successfully implemented\n",
    "# OWNX\twe test our predictions using data on israeli support for the geneva accords, an agreement for a two state solution negotiated by unofficial delegations of israel and the palestinian authority in 2003\n",
    "# OWNX\tthe results demonstrate that israelis are more likely to support agreements that are seen favorably by other israelis, but - contrary to fixed-pie predictions - israeli support for the accords does not diminish simply because a majority of palestinians favors rather than opposes the accords\n",
    "# AIMX\twe show that implementation concerns create a demand among israelis for balance in the degree to which each side favors or opposes the agreement\n",
    "# OWNX\tthe effect of balance is noteworthy in that it creates considerable support for proposals even when a majority of israelis and palestinians oppose the deal\n",
    "### introduction ###\n",
    "# MISC\tnormative models of bargaining and negotiation suggest that if there is potential for mutual benefit, conflicting parties should be able to achieve it  CITATION\n",
    "# CONT\tdescriptive accounts and empirical investigations of negotiation behavior  CITATION , however, suggest that a number of psychological barriers to conflict resolution are likely to make efficient deal making difficult  CITATION\n",
    "# MISC\tfor example, research on cognitive biases associated with egocentric perceptions suggests that negotiators and evaluators of negotiated agreements are likely to exhibit a \"fixed-pie bias\"  CITATION\n",
    "# MISC\tthe fixed-pie bias refers to the belief that any gain for one party will be associated with an equivalent loss to the other party\n",
    "# CONT\tthis belief is a \"bias\" when it persists even in contexts where there is a possibility of compatible interests or mutual benefit\n",
    "# MISC\ta large body of research finds that negotiators are susceptible to the fixed-pie bias prior to, during, and even after negotiations  CITATION\n",
    "# AIMX\tin the current paper we investigate and extend research on fixed pie bias in the context of protracted intergroup conflict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
